#!/usr/bin/env python3
"""
AI æ¨æ–‡æŠ“å–ä¸æ€»ç»“
"""

import requests
import os
import json
from datetime import datetime

# é…ç½®ä»£ç†
PROXIES = {
    'http': 'http://127.0.0.1:7890',
    'https': 'http://127.0.0.1:7890'
}

def get_bearer_token():
    """è·å– Bearer Token"""
    api_key = os.environ.get("X_API_KEY", "")
    api_secret = os.environ.get("X_API_SECRET", "")
    
    if not api_key or not api_secret:
        raise ValueError("X_API_KEY å’Œ X_API_SECRET ç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®")
    
    session = requests.Session()
    session.proxies = PROXIES
    
    oauth_url = "https://api.twitter.com/oauth2/token"
    credentials = f"{api_key}:{api_secret}"
    
    import base64
    b64_credentials = base64.b64encode(credentials.encode()).decode()
    
    headers = {
        "Authorization": f"Basic {b64_credentials}",
        "Content-Type": "application/x-www-form-urlencoded"
    }
    
    data = "grant_type=client_credentials"
    
    response = session.post(oauth_url, headers=headers, data=data, timeout=10)
    
    if response.status_code == 200:
        result = response.json()
        return result.get("access_token")
    else:
        raise Exception(f"è·å– Token å¤±è´¥: {response.status_code}")

def search_tweets(query, max_results=50):
    """æœç´¢æ¨æ–‡"""
    bearer_token = get_bearer_token()
    
    url = "https://api.twitter.com/2/tweets/search/recent"
    params = {
        "query": query,
        "max_results": max_results,
        "tweet.fields": "created_at,author_id,public_metrics"
    }
    headers = {
        "Authorization": f"Bearer {bearer_token}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            return data.get("data", [])
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {response.status_code}")
            print(f"å“åº”: {response.text[:500]}")
            return []
    except Exception as e:
        print(f"âŒ æœç´¢é”™è¯¯: {e}")
        return []

def get_user_tweets(username, max_results=50):
    """è·å–ç”¨æˆ·æ¨æ–‡"""
    bearer_token = get_bearer_token()
    
    user_url = f"https://api.twitter.com/2/users/by/username/{username}"
    headers = {
        "Authorization": f"Bearer {bearer_token}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(user_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            user_data = response.json()
            user_id = user_data.get("data", {}).get("id")
            
            if user_id:
                tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
                params = {
                    "max_results": max_results,
                    "tweet.fields": "created_at,author_id,public_metrics"
                }
                
                all_tweets = []
                next_token = None
                
                while True:
                    if next_token:
                        params["pagination_token"] = next_token
                    
                    response = requests.get(tweets_url, headers=headers, params=params, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        tweets = data.get("data", [])
                        all_tweets.extend(tweets)
                        
                        meta = data.get("meta", {})
                        next_token = meta.get("next_token")
                        
                        if not next_token:
                            break
                    else:
                        break
                
                return all_tweets
            else:
                print(f"âŒ è·å–ç”¨æˆ·å¤±è´¥: {response.status_code}")
                return []
        else:
            print(f"âŒ è·å–ç”¨æˆ·å¤±è´¥: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return []

def create_summary(tweets):
    """åˆ›å»ºæ€»ç»“"""
    if not tweets:
        return "# æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ¨æ–‡"
    
    total_tweets = len(tweets)
    total_likes = sum(tweet.get("public_metrics", {}).get("like_count", 0) for tweet in tweets)
    
    summary = f"""# AI ç›¸å…³æ¨æ–‡æ€»ç»“

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

**æ¨æ–‡æ€»æ•°**: {total_tweets}

---

## ğŸ“ æ¨æ–‡åˆ—è¡¨ (å‰ 20 æ¡)

"""
    
    for i, tweet in enumerate(tweets[:20], 1):
        text = tweet.get("text", "")
        author = tweet.get("author_id", "")
        created = tweet.get("created_at", "")
        metrics = tweet.get("public_metrics", {})
        likes = metrics.get("like_count", 0)
        
        summary += f"""
### {i}. æ¨æ–‡

**å‘å¸ƒæ—¶é—´**: {created}

**å†…å®¹**: {text[:200]}

**äº’åŠ¨æ•°æ®**:
- ğŸ‘ ç‚¹èµ: {likes}
- ğŸ”„ è½¬æ¨: {metrics.get("retweet_count", 0)}
- ğŸ’¬ å¼•ç”¨: {metrics.get("quote_count", 0)}

**ä½œè€… ID**: {author}

---

"""
    
    summary += f"""
## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æ€»æ¨æ–‡æ•°**: {total_tweets}
- **æ€»ç‚¹èµæ•°**: {total_likes}
- **å¹³å‡ç‚¹èµ**: {total_likes // total_tweets if total_tweets > 0 else 0}
- **æ¶‰åŠç”¨æˆ·**: {len(set(tweet.get("author_id", "") for tweet in tweets))}

---

## ğŸ’¡ å†…å®¹åˆ†æ

æ ¹æ®æ¨æ–‡å†…å®¹åˆ†æï¼Œä¸»è¦æ¶‰åŠï¼š
- **AI è¯é¢˜è®¨è®º**
- **æœºå™¨å­¦ä¹ ç ”ç©¶**
- **è¡Œä¸šåŠ¨æ€**
- **æŠ€æœ¯åˆ†äº«**

## ğŸ“„ æ•°æ®ä¿å­˜

å®Œæ•´çš„æ¨æ–‡æ•°æ®å·²ä¿å­˜ä¸º JSON æ ¼å¼ï¼Œä¾¿äºè¿›ä¸€æ­¥åˆ†æå’Œå¤„ç†ã€‚

---
*æœ¬æŠ¥å‘Šç”± AI æ¨æ–‡æŠ“å–å·¥å…·ç”Ÿæˆ*
"""
    
    return summary

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='AI æ¨æ–‡æŠ“å–ä¸æ€»ç»“å·¥å…·')
    parser.add_argument('--search', help='æœç´¢å…³é”®è¯')
    parser.add_argument('--user', help='ç”¨æˆ·å')
    parser.add_argument('--max-results', type=int, default=50, help='æœ€å¤§ç»“æœæ•°')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶', default='/tmp/ai-summary.md')
    
    args = parser.parse_args()
    
    try:
        tweets = []
        
        if args.search:
            print(f"ğŸ” æœç´¢å…³é”®è¯: {args.search}")
            tweets = search_tweets(args.search, args.max_results)
        
        elif args.user:
            print(f"ğŸ‘¤ è·å–ç”¨æˆ·æ¨æ–‡: @{args.user}")
            tweets = get_user_tweets(args.user, args.max_results)
        
        else:
            print("âš ï¸ è¯·æŒ‡å®š --search æˆ– --user")
            return
        
        if tweets:
            print(f"âœ… æ‰¾åˆ° {len(tweets)} æ¡æ¨æ–‡")
            
            # ç”Ÿæˆæ€»ç»“
            summary = create_summary(tweets)
            
            # ä¿å­˜åŸå§‹æ•°æ®
            json_output = args.output.replace('.md', '.json')
            with open(json_output, 'w', encoding='utf-8') as f:
                json.dump(tweets, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æ€»ç»“
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            print(f"\nâœ… æ€»ç»“å·²ä¿å­˜åˆ°: {args.output}")
            print(f"ğŸ“Š æ¨æ–‡æ€»æ•°: {len(tweets)}")
    
    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
