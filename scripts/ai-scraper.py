#!/usr/bin/env python3
"""
AI ç›¸å…³æ¨æ–‡æŠ“å–ä¸æ€»ç»“å·¥å…·
"""

import requests
import os
import base64
import json
import argparse
from datetime import datetime

# é…ç½®ä»£ç†
PROXIES = {
    'http': 'http://127.0.0.1:7890',
    'https': 'http://127.0.0.1:7890'
}

# X API å‡­æ®
CONSUMER_KEY = os.environ.get("X_API_KEY", "")
CONSUMER_SECRET = os.environ.get("X_API_SECRET", "")
ACCESS_TOKEN = os.environ.get("X_ACCESS_TOKEN", "")

def get_oauth_bearer_token():
    """è·å– OAuth 2.0 Bearer Token"""
    if not CONSUMER_KEY or not CONSUMER_SECRET:
        raise ValueError("X_API_KEY å’Œ X_API_SECRET ç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®")
    
    session = requests.Session()
    session.proxies = PROXIES
    
    oauth_url = "https://api.twitter.com/oauth2/token"
    credentials = f"{CONSUMER_KEY}:{CONSUMER_SECRET}"
    b64_credentials = base64.b64encode(credentials.encode()).decode()
    
    headers = {
        "Authorization": f"Basic {b64_credentials}",
        "Content-Type": "application/x-www-form-urlencoded"
    }
    
    data = "grant_type=client_credentials"
    
    response = session.post(oauth_url, headers=headers, data=data, timeout=10)
    
    if response.status_code == 200:
        result = response.json()
        return result.get("access_token"), session
    else:
        raise Exception(f"è·å– Bearer Token å¤±è´¥: {response.text}")

def search_ai_tweets(query, max_results=50):
    """æœç´¢ AI ç›¸å…³æ¨æ–‡"""
    bearer_token, session = get_oauth_bearer_token()
    
    url = "https://api.twitter.com/2/tweets/search/recent"
    params = {
        "query": query,
        "max_results": max_results,
        "tweet.fields": "created_at,author_id,public_metrics,lang,context_annotations"
    }
    headers = {
        "Authorization": f"Bearer {bearer_token}",
        "Content-Type": "application/json"
    }
    
    try:
        response = session.get(url, headers=headers, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            tweets = data.get("data", [])
            print(f"âœ… æ‰¾åˆ° {len(tweets)} æ¡æ¨æ–‡")
            return tweets
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ æœç´¢é”™è¯¯: {e}")
        return []

def get_user_tweets(username, max_results=50):
    """è·å–ç”¨æˆ·æ¨æ–‡"""
    bearer_token, session = get_oauth_bearer_token()
    
    # è·å–ç”¨æˆ· ID
    user_url = f"https://api.twitter.com/2/users/by/username/{username}"
    headers = {
        "Authorization": f"Bearer {bearer_token}",
        "Content-Type": "application/json"
    }
    
    try:
        response = session.get(user_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            user_data = response.json()
            user_id = user_data.get("data", {}).get("id")
            
            if user_id:
                print(f"âœ… ç”¨æˆ· ID: {user_id}")
                
                # è·å–ç”¨æˆ·æ¨æ–‡
                tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
                params = {
                    "max_results": max_results,
                    "tweet.fields": "created_at,author_id,public_metrics,lang,context_annotations"
                }
                
                tweets = []
                next_token = None
                
                while True:
                    if next_token:
                        params["pagination_token"] = next_token
                    
                    response = session.get(tweets_url, headers=headers, params=params, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        batch_tweets = data.get("data", [])
                        tweets.extend(batch_tweets)
                        
                        meta = data.get("meta", {})
                        next_token = meta.get("next_token")
                        
                        print(f"âœ… å·²è·å– {len(tweets)} æ¡æ¨æ–‡...")
                    else:
                        break
                
                print(f"âœ… æ€»å…±è·å–åˆ° {len(tweets)} æ¡æ¨æ–‡")
                return tweets
            else:
                print(f"âŒ è·å–ç”¨æˆ·å¤±è´¥: {response.status_code}")
                return []
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return []

def summarize_to_markdown(tweets, output_file):
    """æ€»ç»“æ¨æ–‡ä¸º Markdown æ–‡æ¡£"""
    if not tweets:
        print("âš ï¸ æ²¡æœ‰æ¨æ–‡å¯æ€»ç»“")
        return
    
    # æŒ‰ä¸»é¢˜åˆ†ç±»
    themes = {
        "AI äººå·¥æ™ºèƒ½": [],
        "æœºå™¨å­¦ä¹  Machine Learning": [],
        "æ·±åº¦å­¦ä¹  Deep Learning": [],
        "è‡ªç„¶è¯­è¨€å¤„ç† NLP": [],
        "è®¡ç®—æœºè§†è§‰ Computer Vision": [],
        "åŠ å¯† Cryptocurrency": [],
        "åŒºå—é“¾ Blockchain": [],
        "äº‘è®¡ç®— Cloud Computing": [],
        "å…¶ä»– Others": []
    }
    
    for tweet in tweets:
        text = tweet.get("text", "").lower()
        author_id = tweet.get("author_id", "")
        created_at = tweet.get("created_at", "")
        metrics = tweet.get("public_metrics", {})
        
        # åˆ†ç±»æ¨æ–‡
        categorized = False
        
        if any(keyword in text for keyword in themes["AI äººå·¥æ™ºèƒ½"]):
            themes["AI äººå·¥æ™ºèƒ½"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["æœºå™¨å­¦ä¹  Machine Learning"]):
            themes["æœºå™¨å­¦ä¹  Machine Learning"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["æ·±åº¦å­¦ä¹  Deep Learning"]):
            themes["æ·±åº¦å­¦ä¹  Deep Learning"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["è‡ªç„¶è¯­è¨€å¤„ç† NLP"]):
            themes["è‡ªç„¶è¯­è¨€å¤„ç† NLP"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["è®¡ç®—æœºè§†è§‰ Computer Vision"]):
            themes["è®¡ç®—æœºè§†è§‰ Computer Vision"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["åŠ å¯† Cryptocurrency"]):
            themes["åŠ å¯† Cryptocurrency"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["åŒºå—é“¾ Blockchain"]):
            themes["åŒºå—é“¾ Blockchain"].append(text)
            categorized = True
        elif any(keyword in text for keyword in themes["äº‘è®¡ç®— Cloud Computing"]):
            themes["äº‘è®¡ç®— Cloud Computing"].append(text)
            categorized = True
        
        if not categorized:
            themes["å…¶ä»– Others"].append(text)
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    markdown = f"""# AI ç›¸å…³æ¨æ–‡æ€»ç»“æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ¨æ–‡æ€»æ•°**: {len(tweets)}

---

## ğŸ“Š ä¸»é¢˜åˆ†å¸ƒ

| ä¸»é¢˜ | æ¨æ–‡æ•° | å æ¯” |
|------|--------|------|
"""
    
    total = len(tweets)
    for theme, tweets_list in themes.items():
        count = len(tweets_list)
        percentage = (count / total * 100) if total > 0 else 0
        markdown += f"| {theme} | {count} | {percentage:.1f}% |\n"
    
    markdown += f"""| æ€»è®¡ | {total} | 100% |
"""

    # å±•ç¤ºå‰ 5 æ¡æ¨æ–‡é¢„è§ˆ
    markdown += """
---

## ğŸ“ æ¨æ–‡é¢„è§ˆ (å‰ 5 æ¡)

"""
    for i, tweet in enumerate(tweets[:5], 1):
        text = tweet.get("text", "")[:100]
        author = tweet.get("author_id", "")
        created = tweet.get("created_at", "")[:10]
        likes = metrics.get("like_count", 0)
        metrics.get("retweet_count", 0)
        retweets = metrics.get("quote_count", 0)
        
        markdown += f"""
### {i}. {created}

**æ¨æ–‡å†…å®¹**: {text}

**äº’åŠ¨æ•°æ®**:
- ğŸ‘ ç‚¹èµ: {likes}
- ğŸ”„ è½¬æ¨: {retweets}
- ğŸ’¬ å¼•ç”¨: {retweets}

**ä½œè€… ID**: {author}

---

"""
    
    # ä¿å­˜ Markdown æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown)
    
    print(f"âœ… æ€»ç»“å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š æ¨æ–‡æ€»æ•°: {len(tweets)}")
    print(f"ğŸ“ ä¸»é¢˜åˆ†ç±»: {len(themes)}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AI æ¨æ–‡æŠ“å–ä¸æ€»ç»“å·¥å…·')
    parser.add_argument('--search', help='æœç´¢å…³é”®è¯ï¼ˆå¦‚ "AI", "äººå·¥æ™ºèƒ½"ï¼‰')
    parser.add_argument('--user', help='ç”¨æˆ·åï¼ˆå¦‚ elonmuskï¼‰')
    parser.add_argument('--max-results', type=int, default=50, help='æœ€å¤§ç»“æœæ•°')
    parser.add_argument('--output', help='è¾“å‡º Markdown æ–‡ä»¶è·¯å¾„', default='/tmp/ai-summary.md')
    
    args = parser.parse_args()
    
    try:
        if args.search:
            print(f"ğŸ” æœç´¢å…³é”®è¯: {args.search}")
            tweets = search_ai_tweets(args.search, args.max_results)
            
        elif args.user:
            print(f"ğŸ‘¤ è·å–ç”¨æˆ·æ¨æ–‡: @{args.user}")
            tweets = get_user_tweets(args.user, args.max_results)
        
        else:
            print("âš ï¸ è¯·æŒ‡å®š --search æˆ– --user å‚æ•°")
            print("\nç¤ºä¾‹:")
            print("  python3 scripts/ai-scraper.py --search 'AI' --max-results 50")
            print("  python3 scripts/ai-scraper.py --user elonmusk --max-results 50")
            return
        
        if tweets:
            summarize_to_markdown(tweets, args.output)
            print(f"\nâœ… æŠ“å–å®Œæˆï¼")
            print(f"ğŸ“„ æ€»ç»“æ–‡ä»¶: {args.output}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print(f"\nğŸ’¡ æç¤º: ç¡®ä¿ X_API_KEY å’Œ X_API_SECRET ç¯å¢ƒå˜é‡å·²è®¾ç½®")

if __name__ == "__main__":
    main()
